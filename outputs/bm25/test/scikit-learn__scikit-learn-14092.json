{
  "instance_id": "scikit-learn__scikit-learn-14092",
  "query": "NCA fails in GridSearch due to too strict parameter checks\nNCA checks its parameters to have a specific type, which can easily fail in a GridSearch due to how param grid is made.\r\n\r\nHere is an example:\r\n```python\r\nimport numpy as np\r\n\r\nfrom sklearn.pipeline import Pipeline\r\nfrom sklearn.model_selection import GridSearchCV\r\nfrom sklearn.neighbors import NeighborhoodComponentsAnalysis\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\n\r\nX = np.random.random_sample((100, 10))\r\ny = np.random.randint(2, size=100)\r\n\r\nnca = NeighborhoodComponentsAnalysis()\r\nknn = KNeighborsClassifier()\r\n\r\npipe = Pipeline([('nca', nca),\r\n                 ('knn', knn)])\r\n                \r\nparams = {'nca__tol': [0.1, 0.5, 1],\r\n          'nca__n_components': np.arange(1, 10)}\r\n          \r\ngs = GridSearchCV(estimator=pipe, param_grid=params, error_score='raise')\r\ngs.fit(X,y)\r\n```\r\n\r\nThe issue is that for `tol`: 1 is not a float, and for  `n_components`: np.int64 is not int\r\n\r\nBefore proposing a fix for this specific situation, I'd like to have your general opinion about parameter checking.  \r\nI like this idea of common parameter checking tool introduced with the NCA PR. What do you think about extending it across the code-base (or at least for new or recent estimators) ?\r\n\r\nCurrently parameter checking is not always done or often partially done, and is quite redundant. For instance, here is the input validation of lda:\r\n```python\r\ndef _check_params(self):\r\n        \"\"\"Check model parameters.\"\"\"\r\n        if self.n_components <= 0:\r\n            raise ValueError(\"Invalid 'n_components' parameter: %r\"\r\n                             % self.n_components)\r\n\r\n        if self.total_samples <= 0:\r\n            raise ValueError(\"Invalid 'total_samples' parameter: %r\"\r\n                             % self.total_samples)\r\n\r\n        if self.learning_offset < 0:\r\n            raise ValueError(\"Invalid 'learning_offset' parameter: %r\"\r\n                             % self.learning_offset)\r\n\r\n        if self.learning_method not in (\"batch\", \"online\"):\r\n            raise ValueError(\"Invalid 'learning_method' parameter: %r\"\r\n                             % self.learning_method)\r\n```\r\nmost params aren't checked and for those who are there's a lot of duplicated code.\r\n\r\nA propose to be upgrade the new tool to be able to check open/closed intervals (currently only closed) and list membership.\r\n\r\nThe api would be something like that:\r\n```\r\ncheck_param(param, name, valid_options)\r\n```\r\nwhere valid_options would be a dict of `type: constraint`. e.g for the `beta_loss` param of `NMF`, it can be either a float or a string in a list, which would give\r\n```\r\nvalid_options = {numbers.Real: None,  # None for no constraint\r\n                 str: ['frobenius', 'kullback-leibler', 'itakura-saito']}\r\n```\r\nSometimes a parameter can only be positive or within a given interval, e.g. `l1_ratio` of `LogisticRegression` must be between 0 and 1, which would give\r\n```\r\nvalid_options = {numbers.Real: Interval(0, 1, closed='both')}\r\n```\r\npositivity of e.g. `max_iter` would be `numbers.Integral: Interval(left=1)`.\n",
  "ground_truth": {
    "files": [
      "sklearn/neighbors/nca.py"
    ],
    "locations": [
      "sklearn/neighbors/nca.py::NeighborhoodComponentsAnalysis",
      "sklearn/neighbors/nca.py::NeighborhoodComponentsAnalysis._validate_params"
    ]
  },
  "predictions": [
    "sklearn/decomposition/online_lda.py::LatentDirichletAllocation._check_params",
    "sklearn/decomposition/nmf.py::non_negative_factorization",
    "sklearn/manifold/t_sne.py::TSNE._fit",
    "sklearn/neighbors/nca.py::NeighborhoodComponentsAnalysis._validate_params",
    "sklearn/utils/validation.py::check_scalar",
    "sklearn/decomposition/nmf.py::_beta_loss_to_float",
    "sklearn/metrics/scorer.py::_check_multimetric_scoring",
    "sklearn/decomposition/tests/test_online_lda.py::test_invalid_params",
    "sklearn/tree/tree.py::DecisionTreeRegressor.fit",
    "sklearn/ensemble/gradient_boosting.py::BaseGradientBoosting.fit"
  ],
  "metadata": {
    "repo": "scikit-learn/scikit-learn",
    "commit": "df7dd8391148a873d157328a4f0328528a0c4ed9",
    "total_functions_indexed": 6613,
    "retrieval_time_seconds": 0.8852348327636719
  },
  "raw_output": "[{\"doc_id\": \"sklearn/decomposition/online_lda.py::LatentDirichletAllocation._check_params\", \"score\": 344.3231978338243}, {\"doc_id\": \"sklearn/decomposition/nmf.py::non_negative_factorization\", \"score\": 309.3243471569804}, {\"doc_id\": \"sklearn/manifold/t_sne.py::TSNE._fit\", \"score\": 294.89134254660644}, {\"doc_id\": \"sklearn/neighbors/nca.py::NeighborhoodComponentsAnalysis._validate_params\", \"score\": 292.27099942890106}, {\"doc_id\": \"sklearn/utils/validation.py::check_scalar\", \"score\": 285.69846414493674}, {\"doc_id\": \"sklearn/decomposition/nmf.py::_beta_loss_to_float\", \"score\": 282.4149694552896}, {\"doc_id\": \"sklearn/metrics/scorer.py::_check_multimetric_scoring\", \"score\": 277.1413651402971}, {\"doc_id\": \"sklearn/decomposition/tests/test_online_lda.py::test_invalid_params\", \"score\": 275.92834191196994}, {\"doc_id\": \"sklearn/tree/tree.py::DecisionTreeRegressor.fit\", \"score\": 274.8663728043581}, {\"doc_id\": \"sklearn/ensemble/gradient_boosting.py::BaseGradientBoosting.fit\", \"score\": 274.0948319993375}]"
}